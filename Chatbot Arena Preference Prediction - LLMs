{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rhaianycezar/chatbot-arena-preference-prediction-llms?scriptVersionId=226392640\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<h1>LLM Classification Finetuning</h1>\n<ul>\n    <li><a href=\"#introducao\">I. Introdução</a></li>\n    <li><a href=\"#\">II. Justificativa</a></li>\n    <li><a href=\"#\">III. Revisão</a></li>\n    <li><a href=\"#\">VI. Metodologia e Coleta de dados</a></li>\n    <li><a href=\"#\">V. Modelagem</a></li>\n    <li><a href=\"#\">VI. Resultados</a></li>\n    <li><a href=\"#\">VII. Conclusão</a></li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"introducao\">I. Introdução</h2>\n<p>Os Modelos de Linguagem de Grande Escala (LLMs) têm se tornado cada vez mais presentes em nosso cotidiano, sendo amplamente utilizados em assistentes virtuais, chatbots e outras aplicações de inteligência artificial. No entanto, um dos desafios na adoção desses modelos é garantir que suas respostas sejam alinhadas às preferências humanas, proporcionando interações mais naturais e satisfatórias. Para resolver essa questão, abordagens baseadas em Aprendizado por Reforço a partir de Feedback Humano (RLHF - Reinforcement Learning from Human Feedback) vêm sendo aplicadas, permitindo que os modelos aprendam com escolhas e preferências reais dos usuários.</p>\n<p>Neste contexto, a competição do Kaggle Chatbot Arena Preference Prediction propõe o desafio de prever qual resposta os usuários irão preferir em um confronto direto entre dois LLMs. A competição fornece um conjunto de dados onde cada entrada contém um prompt, duas respostas geradas por diferentes modelos e a escolha do usuário. O objetivo deste projeto é desenvolver um modelo de machine learning capaz de prever essas preferências com alta precisão, contribuindo para o aprimoramento da personalização e adaptação dos LLMs às necessidades individuais dos usuários.</p>\n<p>Além de sua relevância acadêmica e científica, este estudo tem impacto direto no desenvolvimento de sistemas de IA mais eficientes e alinhados ao comportamento humano. Modelos de linguagem que compreendem melhor as preferências dos usuários podem melhorar significativamente a experiência em aplicações comerciais, educacionais e assistenciais, reduzindo vieses e proporcionando respostas mais úteis. Assim, a pesquisa proposta visa não apenas aprimorar a interação entre humanos e máquinas, mas também contribuir para o avanço da inteligência artificial responsável.</p>","metadata":{}},{"cell_type":"markdown","source":"<h3>1.1 O que é LLMs?</h3>\n<p>LLMs (Large Language Models) são modelos de inteligência artificial treinados em grandes quantidades de dados textuais para entender e gerar linguagem de forma semelhante aos humanos. Eles são baseados em redes neurais profundas, especialmente arquiteturas como os Transformers, que permitem processar e relacionar palavras em um contexto extenso (Vaswani et al., 2017). Modelos populares como <b>GPT-4 (OpenAI, 2023)</b> e <b>BERT (Devlin et al., 2018)</b> são exemplos de LLMs amplamente utilizados em chatbots, assistentes virtuais e mecanismos de busca. Esses modelos continuam evoluindo com o uso de aprendizado por reforço com feedback humano (RLHF), que os ajuda a gerar respostas mais alinhadas às preferências dos usuários (Ouyang et al., 2022).</p>","metadata":{}},{"cell_type":"markdown","source":"<h2>II. Justificativa</h2>\n<p>\nEste projeto é fundamental para melhorar a personalização e a eficácia dos Modelos de Linguagem de Grande Escala (LLMs), garantindo que suas respostas estejam alinhadas com as preferências humanas. A previsibilidade das escolhas dos usuários em interações com chatbots é essencial para tornar a experiência mais natural e satisfatória, beneficiando diversas aplicações, como assistentes virtuais, atendimento ao cliente e educação digital. Além disso, a pesquisa contribui para o avanço do Aprendizado por Reforço a partir de Feedback Humano (RLHF), permitindo a criação de modelos mais éticos e menos enviesados. Ao aprimorar a capacidade dos LLMs de compreender e se adaptar às expectativas dos usuários, este estudo também auxilia no desenvolvimento de sistemas de IA mais confiáveis e responsivos, promovendo impactos positivos tanto na academia quanto na indústria.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<H2>III. Revisão Bibliografica</H2>\n<p>\nA revisão bibliográfica deste estudo aborda três pilares essenciais: Aprendizado por reforço a partir de feedback humano (RLHF), modelos de preferência e vieses em LLMs. Trabalhos anteriores demonstram que RLHF é uma abordagem eficaz para alinhar respostas de modelos de linguagem às preferências humanas, sendo amplamente utilizada no ajuste fino de chatbots e assistentes virtuais. Além disso, pesquisas sobre modelos de recompensa e previsão de preferências destacam a importância de técnicas de machine learning para entender padrões nas escolhas dos usuários. Por fim, estudos sobre viés em LLMs mostram que fatores como verbosidade, posição da resposta e autopromoção podem influenciar a percepção do usuário, tornando essencial a aplicação de técnicas que reduzam esses efeitos para garantir previsões mais precisas e justas.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<h2>VI. Requisitos</h2>\n<ul>\n    <li>Objetivo: Prever qual resposta os usuários preferirão em um confronto entre dois modelos de linguagem (LLMs).\nDados fornecidos: Conversas extraídas do Chatbot Arena, com prompts, respostas de dois LLMs e a escolha do usuário.</li>\n    <li>Tarefa principal: Desenvolver um modelo de machine learning para prever as preferências humanas com alta precisão.</li> \n    <li>Desafios envolvidos:</li>\n    <ol>\n    <li>Viés de posição (respostas apresentadas primeiro podem ser favorecidas).</li>\n    <li>Viés de verbosidade (respostas mais longas podem ser percebidas como melhores).</li>\n    <li>Viés de autopromoção (respostas que elogiam o próprio modelo podem influenciar a escolha do usuário).</li>\n    </ol>\n    <li>Métrica de avaliação: Perda logarítmica entre as probabilidades previstas e os valores reais da escolha do usuário.</li>\n    <li>Formato da submissão: Arquivo CSV contendo as probabilidades de preferência para cada modelo e para empate.</li>\n    <li>Ferramentas recomendadas: Kaggle Notebooks (ambiente com suporte a Python, Jupyter e GPUs gratuitas).</li>\n    <li>Competição contínua: A tabela de classificação é atualizada periodicamente e inscrições com mais de dois meses são invalidadas.</li>\n    <li>Site da competição: https://www.kaggle.com/competitions/llm-classification-finetuning</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndataTrain = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\ndataTest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:12:55.795925Z","iopub.execute_input":"2025-03-07T03:12:55.796319Z","iopub.status.idle":"2025-03-07T03:12:58.417572Z","shell.execute_reply.started":"2025-03-07T03:12:55.796285Z","shell.execute_reply":"2025-03-07T03:12:58.416462Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>V. Metodologia</h2>\n<h3>5.1. Coleta de Dados</h3>\n<p>Os dados utilizados neste projeto vêm da Chatbot Arena, onde usuários interagem com dois chatbots diferentes para responder a um mesmo prompt. Após receber as respostas, os usuários escolhem qual preferem.</p>\n\nA base de dados contém:\n<ul>\n    <li>ID do participante</li>\n    <li>Modelo A e Modelo B (identificadores dos chatbots)</li>\n    <li>Prompt (pergunta feita pelo usuário)</li>\n    <li>Resposta A e Resposta B (respostas dos chatbots)</li>\n    <li>Winner A, Winner B, Winner Tie (indicam qual resposta foi escolhida)</li>\n</ul>\n<p>Esses dados já estão coletados e prontos para serem processados e utilizados no treinamento do modelo.</p>","metadata":{}},{"cell_type":"code","source":"dataTrain.head(5)","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-03-07T03:12:58.418756Z","iopub.execute_input":"2025-03-07T03:12:58.419063Z","iopub.status.idle":"2025-03-07T03:12:58.436075Z","shell.execute_reply.started":"2025-03-07T03:12:58.419037Z","shell.execute_reply":"2025-03-07T03:12:58.435119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def searchModel():\n    for j in ['model_a','model_b']:\n        a=False\n        for k in chatBot:\n            if k == r[j]:\n                a = True\n                break\n        if a==False:\n            chatBot.update({r[j]:{'winner':0,'loss':0,'round':0}})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:12:58.438302Z","iopub.execute_input":"2025-03-07T03:12:58.438667Z","iopub.status.idle":"2025-03-07T03:12:58.448839Z","shell.execute_reply.started":"2025-03-07T03:12:58.438636Z","shell.execute_reply":"2025-03-07T03:12:58.447634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def winModel():\n     chatBot[r['model_a']]['round']+=1\n     chatBot[r['model_b']]['round']+=1\n     if r['winner_model_a']==1:\n         chatBot[r['model_a']]['winner']+=1\n         chatBot[r['model_b']]['loss']+=1\n     elif r['winner_model_b']==1:\n         chatBot[r['model_b']]['winner']+=1\n         chatBot[r['model_a']]['loss']+=1\n     else:\n         chatBot['winner_tie']['round']+=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:12:58.450163Z","iopub.execute_input":"2025-03-07T03:12:58.450443Z","iopub.status.idle":"2025-03-07T03:12:58.460466Z","shell.execute_reply.started":"2025-03-07T03:12:58.450419Z","shell.execute_reply":"2025-03-07T03:12:58.459413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quest = {'char':0,'words':0}\nmodelA = {'char':0,'words':0}\nmodelB = {'char':0,'words':0}\nchatBot = {'winner_tie':{'winner':0,'loss':0,'round':0}}\nindex = 0\n\nfor i,r in dataTrain.iterrows():\n    quest['char'] += len(r['prompt'])\n    quest['words'] += len(r['prompt'].split(' '))\n\n    modelA['char'] += len(r['response_a'])\n    modelA['words'] += len(r['response_a'].split(' '))\n\n    modelB['char'] += len(r['response_b'])\n    modelB['words'] += len(r['response_b'].split(' '))\n\n    searchModel()\n\n    winModel()\n\n\nprint(\"Numero de registros %d \\n%d modelos testados \\n%d empates\\n\\n\"%(\n    len(dataTrain), len(chatBot)-1, chatBot['winner_tie']['round']))\nprint(\"=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\")\nprint(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n    quest['char']/len(dataTrain),\n    quest['words']/len(dataTrain)))\n\nprint(\"=======MÉDIA DE CARACTERES E PALAVRAS MODELO A =========\")\nprint(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n    modelA['char']/len(dataTrain),\n    modelA['words']/len(dataTrain)))\n\nprint(\"=======MÉDIA DE CARACTERES E PALAVRAS MODELO B =========\")\nprint(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n    modelB['char']/len(dataTrain),\n    modelB['words']/len(dataTrain)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:12:58.461552Z","iopub.execute_input":"2025-03-07T03:12:58.462137Z","iopub.status.idle":"2025-03-07T03:13:11.175738Z","shell.execute_reply.started":"2025-03-07T03:12:58.462089Z","shell.execute_reply":"2025-03-07T03:13:11.174594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatBot = pd.DataFrame(chatBot)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:11.176748Z","iopub.execute_input":"2025-03-07T03:13:11.177062Z","iopub.status.idle":"2025-03-07T03:13:11.184274Z","shell.execute_reply.started":"2025-03-07T03:13:11.177035Z","shell.execute_reply":"2025-03-07T03:13:11.183229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatBot = chatBot.T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:11.18541Z","iopub.execute_input":"2025-03-07T03:13:11.185826Z","iopub.status.idle":"2025-03-07T03:13:11.204657Z","shell.execute_reply.started":"2025-03-07T03:13:11.185788Z","shell.execute_reply":"2025-03-07T03:13:11.203432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatBot['Taxa de Vitória (%)'] = (chatBot['winner'] / chatBot['round']) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:11.207299Z","iopub.execute_input":"2025-03-07T03:13:11.207702Z","iopub.status.idle":"2025-03-07T03:13:11.225024Z","shell.execute_reply.started":"2025-03-07T03:13:11.207666Z","shell.execute_reply":"2025-03-07T03:13:11.223893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatBot.sort_values('Taxa de Vitória (%)', ascending=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:11.226281Z","iopub.execute_input":"2025-03-07T03:13:11.226587Z","iopub.status.idle":"2025-03-07T03:13:11.246474Z","shell.execute_reply.started":"2025-03-07T03:13:11.226556Z","shell.execute_reply":"2025-03-07T03:13:11.245266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatBot.loc['winner_tie', 'Taxa de Vitória (%)'] = (\n    chatBot.loc['winner_tie', 'round'] / len(dataTrain)\n) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:11.247644Z","iopub.execute_input":"2025-03-07T03:13:11.247945Z","iopub.status.idle":"2025-03-07T03:13:11.264768Z","shell.execute_reply.started":"2025-03-07T03:13:11.24791Z","shell.execute_reply":"2025-03-07T03:13:11.263792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatBot['Taxa de Vitória (%)'] = chatBot['Taxa de Vitória (%)'].round(2) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:11.265706Z","iopub.execute_input":"2025-03-07T03:13:11.265971Z","iopub.status.idle":"2025-03-07T03:13:11.280963Z","shell.execute_reply.started":"2025-03-07T03:13:11.265949Z","shell.execute_reply":"2025-03-07T03:13:11.27995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=chatBot.index, y=chatBot['Taxa de Vitória (%)'], palette=\"coolwarm\")\nplt.xticks(rotation=90)\nplt.ylabel(\"Taxa de Vitória (%)\")\nplt.title(\"Taxa de Vitória\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:11.282041Z","iopub.execute_input":"2025-03-07T03:13:11.282309Z","iopub.status.idle":"2025-03-07T03:13:12.662156Z","shell.execute_reply.started":"2025-03-07T03:13:11.282286Z","shell.execute_reply":"2025-03-07T03:13:12.660987Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Taxa de Vitória: Análise:**\nModelos como GPT-4-1106-preview e Claude 2.0 provavelmente terão as maiores taxas de vitória, reforçando sua eficiência.<br/>\nModelos como ChatGLM3-6B e OpenChat-3.5 aparece com taxas menores, evidenciando seu desempenho inferior.<br/>\nEsse gráfico destaca quais modelos têm maior sucesso nas rodadas disputadas.","metadata":{}},{"cell_type":"code","source":"cBot = {}\nfor i,r in chatBot.head(11).iterrows():\n    if i != 'winner_tie':\n        cBot.update({i:r})\nfor i,r in chatBot.tail(10).iterrows():\n    cBot.update({i:r})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:12.663316Z","iopub.execute_input":"2025-03-07T03:13:12.663981Z","iopub.status.idle":"2025-03-07T03:13:12.676614Z","shell.execute_reply.started":"2025-03-07T03:13:12.663936Z","shell.execute_reply":"2025-03-07T03:13:12.675444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cBot = pd.DataFrame(cBot).T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:12.677547Z","iopub.execute_input":"2025-03-07T03:13:12.677836Z","iopub.status.idle":"2025-03-07T03:13:12.700096Z","shell.execute_reply.started":"2025-03-07T03:13:12.677812Z","shell.execute_reply":"2025-03-07T03:13:12.699014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cBot.groupby(list(cBot))['round'].sum().plot.pie(\n    autopct='%1.1f%%', figsize=(10, 10), labels=cBot.index)\nplt.ylabel(\"Rodadas\")\nplt.xlabel(\"10 modelos com mais e menos rodadas\")\nplt.title(\"Distribuição das Rodadas por Modelo\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:12.701011Z","iopub.execute_input":"2025-03-07T03:13:12.701291Z","iopub.status.idle":"2025-03-07T03:13:13.042309Z","shell.execute_reply.started":"2025-03-07T03:13:12.701268Z","shell.execute_reply":"2025-03-07T03:13:13.041135Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Participação de cada modelo no total de rodadas disputadas.** \nModelos que participaram de mais rodadas (como GPT-4-1106-preview) terão fatias maiores, indicando maior amostragem nos testes.<br/>\nModelos que participaram de poucas rodadas terão fatias menores, o que pode impactar a confiabilidade dos seus resultados.<br/>\nEsse gráfico é útil para identificar se o desempenho de um modelo foi baseado em um número significativo de rodadas ou se pode ser um caso isolado.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.scatterplot(x = cBot['round'], \n                y = cBot['winner'], \n                hue = cBot.index, \n                palette=\"coolwarm\")\nplt.xlabel(\"Total de Rodadas\")\nplt.ylabel(\"Total de Vitórias\")\nplt.title(\"Correlação entre Rodadas e Vitórias\\n 10 modelos com mais/menos\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:13.043668Z","iopub.execute_input":"2025-03-07T03:13:13.044059Z","iopub.status.idle":"2025-03-07T03:13:13.735817Z","shell.execute_reply.started":"2025-03-07T03:13:13.044021Z","shell.execute_reply":"2025-03-07T03:13:13.734743Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Relação entre o número de rodadas disputadas e o número de vitórias**\nModelos com alto número de rodadas e alto número de vitórias estarão na parte superior direita do gráfico, mostrando desempenho consistente.<br/>\nModelos com muitas rodadas, mas poucas vitórias, estarão na parte inferior direita, sugerindo baixo desempenho.<br/>\nModelos com poucas rodadas e poucas vitórias ficarão na parte inferior esquerda, indicando menor relevância no teste.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nsns.heatmap(\n    cBot.pivot(columns='round', values='Taxa de Vitória (%)'), \n    cmap='coolwarm', \n    annot=True\n)\nplt.xlabel(\"Total de Rodadas\")\nplt.ylabel(\"Taxa de Vitória\")\nplt.title(\"Taxa de Vitória por Modelo e Rodadas\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:13.736827Z","iopub.execute_input":"2025-03-07T03:13:13.737174Z","iopub.status.idle":"2025-03-07T03:13:14.29688Z","shell.execute_reply.started":"2025-03-07T03:13:13.737147Z","shell.execute_reply":"2025-03-07T03:13:14.295903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.plot(chatBot['round'][1:], color='tab:blue', label='Rodadas', linestyle='-')\nplt.plot(chatBot['winner'][1:], color='tab:orange', label='Vitória', linestyle='--')\nplt.xticks(rotation=90)\nplt.xlabel('Rodadas')\nplt.ylabel('Vitórias')\nplt.title('Taxa de Vitória ao Longo das Rodadas')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:13:14.298141Z","iopub.execute_input":"2025-03-07T03:13:14.298521Z","iopub.status.idle":"2025-03-07T03:13:14.907164Z","shell.execute_reply.started":"2025-03-07T03:13:14.298447Z","shell.execute_reply":"2025-03-07T03:13:14.906052Z"}},"outputs":[],"execution_count":null}]}
